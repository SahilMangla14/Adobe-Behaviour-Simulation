{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup OAuth for accessing PALM finetuned model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade -q google-api-python-client google-auth-httplib2 google-auth-oauthlib\n",
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yamup\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Install the client library and import necessary modules.\n",
    "# !pip install google-generativeai\n",
    "import google.generativeai as palm\n",
    "import base64\n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/generative-language.tuning']\n",
    "\n",
    "def load_creds():\n",
    "    \"\"\"Converts `oauth-client-id.json` to a credential object.\n",
    "\n",
    "    This function caches the generated tokens to minimize the use of the\n",
    "    consent screen.\n",
    "    \"\"\"\n",
    "    creds = None\n",
    "    # The file token.json stores the user's access and refresh tokens, and is\n",
    "    # created automatically when the authorization flow completes for the first\n",
    "    # time.\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'oauth-client-id.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available base models: ['models/chat-bison-001', 'models/text-bison-001', 'models/embedding-gecko-001', 'models/gemini-pro', 'models/gemini-pro-vision', 'models/embedding-001', 'models/aqa']\n",
      "My tuned models: ['tunedModels/adobemid-fwdqq210yvfu', 'tunedModels/palmfinetuningapproach3-kdvh8t1tct5a']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import google.generativeai as palm\n",
    "\n",
    "creds = load_creds()\n",
    "\n",
    "palm.configure(credentials=creds)\n",
    "\n",
    "print('Available base models:', [m.name for m in palm.list_models()])\n",
    "print('My tuned models:', [m.name for m in palm.list_tuned_models()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'tunedModels/adobemid-fwdqq210yvfu'\n",
    "model = palm.get_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_name \n",
    "temperature = 0 \n",
    "candidate_count = 1 \n",
    "top_k = 40 \n",
    "top_p = 0.95 \n",
    "max_output_tokens = 1024 \n",
    "\n",
    "defaults = {\n",
    "  'model': model,\n",
    "  'temperature': temperature,\n",
    "  'candidate_count': candidate_count,\n",
    "  'top_k': top_k,\n",
    "  'top_p': top_p,\n",
    "  'max_output_tokens': max_output_tokens,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt, defaults):\n",
    "    \"\"\"Returns the response from the model.\"\"\"\n",
    "    response = palm.generate_text(**defaults,prompt=prompt)\n",
    "    \n",
    "    if len(response.candidates) == 0:\n",
    "        return ' '\n",
    "    return response.candidates[0]['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"Context: The tweet was posted by '{company}' on '{date}' having '{like}' likes. The tweet contains the image with the following description - '{media_desc}'. The username of the company is '{username}'. Question: What is the tweet that was written based on the given information?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "test_tweet = np.load('../data/tweet_desc.npy', allow_pickle=True)[1000:2000]\n",
    "test_likes = np.load('../data/tweet_likes.npy', allow_pickle=True)[1000:2000]\n",
    "\n",
    "generated_and_actual = []\n",
    "\n",
    "for i in range(len(test_tweet)):\n",
    "    try:\n",
    "        tweet = test_tweet[i]\n",
    "        like = test_likes[i]\n",
    "        company = tweet['company']\n",
    "        date = tweet['date']\n",
    "        media_desc = tweet['media']\n",
    "        username = tweet['username']\n",
    "\n",
    "        prompt = prompt_template.format(company=company, date=date, like=like, media_desc=media_desc, username=username)\n",
    "        generated_response = get_response(prompt, defaults)\n",
    "\n",
    "\n",
    "        generated_and_actual.append({\n",
    "            'generated': generated_response,\n",
    "            'actual': tweet['content']\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}. index: {i}\")\n",
    "        \n",
    "df = pd.DataFrame(generated_and_actual)\n",
    "df.to_csv('../saved/generated_and_actual_appr_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../saved/generated_and_actual_appr_1.csv')\n",
    "\n",
    "for i in range(len(df)):\n",
    "    item = df.loc[i, 'generated']\n",
    "    if item.startswith('Answer:') or item.startswith('Solution:'):\n",
    "        df.loc[i, 'generated'] = item.split(':')[1].strip()\n",
    "\n",
    "df.to_csv('../saved/generated_and_actual_appr_1_updated.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
